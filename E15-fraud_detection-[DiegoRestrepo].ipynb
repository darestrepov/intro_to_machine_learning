{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15\n",
    "\n",
    "# Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "- Fraud Detection Dataset from Microsoft Azure: [data](http://gallery.cortanaintelligence.com/Experiment/8e9fe4e03b8b4c65b9ca947c72b8e463)\n",
    "\n",
    "Fraud detection is one of the earliest industrial applications of data mining and machine learning. Fraud detection is typically handled as a binary classification problem, but the class population is unbalanced because instances of fraud are usually very rare compared to the overall volume of transactions. Moreover, when fraudulent transactions are discovered, the business typically takes measures to block the accounts from transacting to prevent further losses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accountAge</th>\n",
       "      <th>digitalItemCount</th>\n",
       "      <th>sumPurchaseCount1Day</th>\n",
       "      <th>sumPurchaseAmount1Day</th>\n",
       "      <th>sumPurchaseAmount30Day</th>\n",
       "      <th>paymentBillingPostalCode - LogOddsForClass_0</th>\n",
       "      <th>accountPostalCode - LogOddsForClass_0</th>\n",
       "      <th>paymentBillingState - LogOddsForClass_0</th>\n",
       "      <th>accountState - LogOddsForClass_0</th>\n",
       "      <th>paymentInstrumentAgeInAccount</th>\n",
       "      <th>ipState - LogOddsForClass_0</th>\n",
       "      <th>transactionAmount</th>\n",
       "      <th>transactionAmountUSD</th>\n",
       "      <th>ipPostalCode - LogOddsForClass_0</th>\n",
       "      <th>localHour - LogOddsForClass_0</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>720.25</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>0.421214</td>\n",
       "      <td>1.312186</td>\n",
       "      <td>0.566395</td>\n",
       "      <td>3279.574306</td>\n",
       "      <td>1.218157</td>\n",
       "      <td>599.00</td>\n",
       "      <td>626.164650</td>\n",
       "      <td>1.259543</td>\n",
       "      <td>4.745402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1185.44</td>\n",
       "      <td>2530.37</td>\n",
       "      <td>0.538996</td>\n",
       "      <td>0.481838</td>\n",
       "      <td>4.401370</td>\n",
       "      <td>4.500157</td>\n",
       "      <td>61.970139</td>\n",
       "      <td>4.035601</td>\n",
       "      <td>1185.44</td>\n",
       "      <td>1185.440000</td>\n",
       "      <td>3.981118</td>\n",
       "      <td>4.921349</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>5.096396</td>\n",
       "      <td>3.056357</td>\n",
       "      <td>3.155226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.314186</td>\n",
       "      <td>32.09</td>\n",
       "      <td>32.090000</td>\n",
       "      <td>5.008490</td>\n",
       "      <td>4.742303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>5.096396</td>\n",
       "      <td>3.331154</td>\n",
       "      <td>3.331239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.529398</td>\n",
       "      <td>133.28</td>\n",
       "      <td>132.729554</td>\n",
       "      <td>1.324925</td>\n",
       "      <td>4.745402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>132.73</td>\n",
       "      <td>5.412885</td>\n",
       "      <td>0.342945</td>\n",
       "      <td>5.563677</td>\n",
       "      <td>4.086965</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>3.529398</td>\n",
       "      <td>543.66</td>\n",
       "      <td>543.660000</td>\n",
       "      <td>2.693451</td>\n",
       "      <td>4.876771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accountAge  digitalItemCount  sumPurchaseCount1Day  sumPurchaseAmount1Day  \\\n",
       "0        2000                 0                     0                   0.00   \n",
       "1          62                 1                     1                1185.44   \n",
       "2        2000                 0                     0                   0.00   \n",
       "3           1                 1                     0                   0.00   \n",
       "4           1                 1                     0                   0.00   \n",
       "\n",
       "   sumPurchaseAmount30Day  paymentBillingPostalCode - LogOddsForClass_0  \\\n",
       "0                  720.25                                      5.064533   \n",
       "1                 2530.37                                      0.538996   \n",
       "2                    0.00                                      5.064533   \n",
       "3                    0.00                                      5.064533   \n",
       "4                  132.73                                      5.412885   \n",
       "\n",
       "   accountPostalCode - LogOddsForClass_0  \\\n",
       "0                               0.421214   \n",
       "1                               0.481838   \n",
       "2                               5.096396   \n",
       "3                               5.096396   \n",
       "4                               0.342945   \n",
       "\n",
       "   paymentBillingState - LogOddsForClass_0  accountState - LogOddsForClass_0  \\\n",
       "0                                 1.312186                          0.566395   \n",
       "1                                 4.401370                          4.500157   \n",
       "2                                 3.056357                          3.155226   \n",
       "3                                 3.331154                          3.331239   \n",
       "4                                 5.563677                          4.086965   \n",
       "\n",
       "   paymentInstrumentAgeInAccount  ipState - LogOddsForClass_0  \\\n",
       "0                    3279.574306                     1.218157   \n",
       "1                      61.970139                     4.035601   \n",
       "2                       0.000000                     3.314186   \n",
       "3                       0.000000                     3.529398   \n",
       "4                       0.001389                     3.529398   \n",
       "\n",
       "   transactionAmount  transactionAmountUSD  ipPostalCode - LogOddsForClass_0  \\\n",
       "0             599.00            626.164650                          1.259543   \n",
       "1            1185.44           1185.440000                          3.981118   \n",
       "2              32.09             32.090000                          5.008490   \n",
       "3             133.28            132.729554                          1.324925   \n",
       "4             543.66            543.660000                          2.693451   \n",
       "\n",
       "   localHour - LogOddsForClass_0  Label  \n",
       "0                       4.745402      0  \n",
       "1                       4.921349      0  \n",
       "2                       4.742303      0  \n",
       "3                       4.745402      0  \n",
       "4                       4.876771      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/albahnsen/PracticalMachineLearningClass/master/datasets/15_fraud_detection.csv.zip'\n",
    "df = pd.read_csv(url, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((138721, 16), 797, 0.0057453449730033666)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, df.Label.sum(), df.Label.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.1\n",
    "\n",
    "Estimate a Logistic Regression and a Decision Tree\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score\n",
    "* F_Beta-Score (Beta=10)\n",
    "\n",
    "Comment about the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    137924\n",
       "1       797\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['Label'], axis=1)\n",
    "y = df['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state = 42)\n",
    "\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0. 0. 0. ... 0. 0. 0.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-46e700d4c252>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mX_train_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mX_test_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0my_test_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, y, copy)\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m         X = check_array(X, accept_sparse='csr', copy=copy, warn_on_dtype=True,\n\u001b[1;32m--> 681\u001b[1;33m                         estimator=self, dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    439\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    442\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m             \u001b[1;31m# To ensure that array flags are maintained\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0. 0. 0. ... 0. 0. 0.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Standarizar datos:\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# Fit on training set only.\n",
    "scaler.fit(X_train)\n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Varianza acumulativa')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA().fit(X_train_s)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Número de componentes')\n",
    "plt.ylabel('Varianza acumulativa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la gráfica se infiere que n_components = 10 (explican el 80% de los datos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total explanation:  0.8284903056008417\n"
     ]
    }
   ],
   "source": [
    "PCA_1 = PCA(n_components = 10)\n",
    "# Fit PCA on training set\n",
    "PCA_1.fit(X_train_s)\n",
    "# Apply the mapping (transform) to both the training set and the test set.\n",
    "X_train = PCA_1.transform(X_train_s)\n",
    "X_test = PCA_1.transform(X_test_s)\n",
    "y_test = PCA_1.transform(y_test)\n",
    "\n",
    "print(\"Total explanation: \",sum(PCA_1.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Label'], axis=1)\n",
    "y = df['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver='liblinear',C=1e9)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9939053693914107\n",
      "F1-score: 0.0\n",
      "F_Beta-Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_pred, y_test))\n",
    "print(\"F1-score:\",metrics.f1_score(y_pred, y_test))\n",
    "print(\"F_Beta-Score:\",metrics.fbeta_score(y_pred, y_test,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = []\n",
    "accuracy_scores.append(['-','logistic', -1, -1,metrics.accuracy_score(y_pred, y_test), metrics.f1_score(y_pred, y_test),metrics.fbeta_score(y_pred, y_test,10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate a DecisionTreeRegressor (with random_state=1)\n",
    "\n",
    "arbol = DecisionTreeClassifier(random_state=1)\n",
    "arbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol.fit(X_train,y_train)\n",
    "y_pred = arbol.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9886408318406221\n",
      "F1-score: 0.12457912457912457\n",
      "F_Beta-Score: 0.11614607614607615\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_pred, y_test))\n",
    "print(\"F1-score:\",metrics.f1_score(y_pred, y_test))\n",
    "print(\"F_Beta-Score:\",metrics.fbeta_score(y_pred, y_test,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores.append(['-','DecisionTree', -1, -1,metrics.accuracy_score(y_pred, y_test), metrics.f1_score(y_pred, y_test),metrics.fbeta_score(y_pred, y_test,10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.2\n",
    "\n",
    "Under-sample the negative class using random-under-sampling\n",
    "\n",
    "Which is parameter for target_percentage did you choose?\n",
    "How the results change?\n",
    "\n",
    "**Only apply under-sampling to the training set, evaluate using the whole test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UnderSampling(X, y, target_percentage=0.5, seed=None):\n",
    "    # Assuming minority class is the positive\n",
    "    n_samples = y.shape[0]\n",
    "    n_samples_0 = (y == 0).sum()\n",
    "    n_samples_1 = (y == 1).sum()\n",
    "\n",
    "    n_samples_0_new =  n_samples_1 / target_percentage - n_samples_1\n",
    "    n_samples_0_new_per = n_samples_0_new / n_samples_0\n",
    "\n",
    "    filter_ = y == 0\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    rand_1 = np.random.binomial(n=1, p=n_samples_0_new_per, size=n_samples)\n",
    "    \n",
    "    filter_ = filter_ & rand_1\n",
    "    filter_ = filter_ | (y == 1)\n",
    "    filter_ = filter_.astype(bool)\n",
    "    \n",
    "    return X[filter_], y[filter_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the original data\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_two_classes(X, y, subplot=False, size=(10, 10)):\n",
    "    # Plot the two classes\n",
    "    \n",
    "    if subplot == False:\n",
    "        fig, subplot = plt.subplots(nrows=1, ncols=1, figsize=size)\n",
    "        \n",
    "    subplot.scatter(X[y==0, 0], X[y==0, 1], label=\"Class #0\", \n",
    "                    alpha=0.5, s=70)\n",
    "    subplot.scatter(X[y==1, 0], X[y==1, 1], label=\"Class #1\", \n",
    "                    alpha=0.5, s=70)\n",
    "    subplot.legend()\n",
    "    return subplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45778, 15)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9318231464895802 F1-Score: 0.14843110504774898 F-Beta: 0.08097266229459878\n",
      "Accuracy: 0.859736117785836 F1-Score: 0.0781048097631012 F-Beta: 0.04104740203952038\n",
      "Accuracy: 0.8003844641530866 F1-Score: 0.056576502168077636 F-Beta: 0.029397423980879033\n",
      "Accuracy: 0.7364236095941282 F1-Score: 0.043443792611384174 F-Beta: 0.022423076143982822\n",
      "Accuracy: 0.6818122242125039 F1-Score: 0.03638528711299286 F-Beta: 0.018711578947368423\n",
      "Accuracy: 0.6425575604001922 F1-Score: 0.03251936380299178 F-Beta: 0.016690954434145096\n",
      "Accuracy: 0.5905238324085805 F1-Score: 0.028504793988079816 F-Beta: 0.014600938350133394\n"
     ]
    }
   ],
   "source": [
    "for target_percentage in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]:\n",
    "    X_u, y_u = UnderSampling(X, y, target_percentage, 1)\n",
    "    \n",
    "    logreg.fit(X_u,y_u)\n",
    "    y_pred=logreg.predict(X_test)\n",
    "    accuracy_scores.append(['under-sampling','logistic',target_percentage,-1,metrics.accuracy_score(y_pred, y_test), metrics.f1_score(y_pred, y_test),metrics.fbeta_score(y_pred, y_test,10)])   \n",
    "\n",
    "    arbol.fit(X_u,y_u)\n",
    "    y_pred=arbol.predict(X_test)\n",
    "    accuracy_scores.append(['under-sampling','DecisionTree',target_percentage,-1,metrics.accuracy_score(y_pred, y_test), metrics.f1_score(y_pred, y_test),metrics.fbeta_score(y_pred, y_test,10)])   \n",
    " \n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_pred, y_test),\"F1-Score:\",metrics.f1_score(y_pred, y_test),\"F-Beta:\",metrics.fbeta_score(y_pred, y_test,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.3\n",
    "\n",
    "Same analysis using random-over-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Label'], axis=1)\n",
    "y = df['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def OverSampling(X, y, target_percentage=0.5, seed=None):\n",
    "    # Assuming minority class is the positive\n",
    "    n_samples = y.shape[0]\n",
    "    n_samples_0 = (y == 0).sum()\n",
    "    n_samples_1 = (y == 1).sum()\n",
    "\n",
    "    n_samples_1_new =  -target_percentage * n_samples_0 / (target_percentage- 1)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    filter_ = np.random.choice(X[y == 1].shape[0], int(n_samples_1_new))\n",
    "    # filter_ is within the positives, change to be of all\n",
    "    filter_ = np.nonzero(y == 1)[0][filter_]\n",
    "    \n",
    "    filter_ = np.concatenate((filter_, np.nonzero(y == 0)[0]), axis=0)\n",
    "    \n",
    "    return X.iloc[filter_], y.iloc[filter_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9890558783695225 F1-Score: 0.12869565217391304 FBeta: 0.12343517753922378\n",
      "Accuracy: 0.9896238367774913 F1-Score: 0.1316270566727605 FBeta: 0.13233848953594177\n",
      "Accuracy: 0.9897330595482546 F1-Score: 0.14233576642335768 FBeta: 0.1428467815049864\n",
      "Accuracy: 0.9897985932107126 F1-Score: 0.12710280373831775 FBeta: 0.1306945765937203\n",
      "Accuracy: 0.9896238367774913 F1-Score: 0.1252302025782689 FBeta: 0.12683287165281626\n"
     ]
    }
   ],
   "source": [
    "for target_percentage in [0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "    X_u, y_u = OverSampling(X_train, y_train, target_percentage, 42)\n",
    "########## logistic regression #############  \n",
    "    logreg.fit(X_u,y_u)\n",
    "    y_pred=logreg.predict(X_test)\n",
    "    accuracy_scores.append(['over-sampling','logistic',target_percentage,-1,metrics.accuracy_score(y_pred, y_test), metrics.f1_score(y_pred, y_test),metrics.fbeta_score(y_pred, y_test,10)])   \n",
    "########## decision tree#############    \n",
    "    arbol.fit(X_u,y_u)\n",
    "    y_pred=arbol.predict(X_test)\n",
    "    accuracy_scores.append(['over-sampling','DecisionTree',target_percentage,-1,metrics.accuracy_score(y_pred, y_test), metrics.f1_score(y_pred, y_test),metrics.fbeta_score(y_pred, y_test,10)])   \n",
    "    \n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_pred, y_test),\"F1-Score:\",metrics.f1_score(y_pred, y_test),\"FBeta:\",metrics.fbeta_score(y_pred, y_test,10))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.4 (3 points)\n",
    "\n",
    "Evaluate the results using SMOTE\n",
    "\n",
    "Which parameters did you choose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = y.shape[0]\n",
    "n_samples_0 = (y == 0).sum()\n",
    "n_samples_1 = (y == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMOTE(X, y, target_percentage=0.5, k=5, seed=None):\n",
    "    \n",
    "    # New samples\n",
    "    n_samples_1_new =  int(-target_percentage * n_samples_0 / (target_percentage- 1) - n_samples_1)\n",
    "    \n",
    "    # A matrix to store the synthetic samples\n",
    "    new = np.zeros((n_samples_1_new, X.shape[1]))\n",
    "    \n",
    "    # Create seeds\n",
    "    np.random.seed(seed)\n",
    "    seeds = np.random.randint(1, 1000000, 3)\n",
    "    \n",
    "    # Select examples to use as base\n",
    "    np.random.seed(seeds[0])\n",
    "    sel_ = np.random.choice(y[y==1].shape[0], n_samples_1_new)\n",
    "    \n",
    "    # Define random seeds (2 per example)\n",
    "    np.random.seed(seeds[1])\n",
    "    nn__ = np.random.choice(k, n_samples_1_new)\n",
    "    np.random.seed(seeds[2])\n",
    "    steps = np.random.uniform(size=n_samples_1_new)  \n",
    "\n",
    "    # For each selected examples create one synthetic case\n",
    "    for i, sel in enumerate(sel_):\n",
    "        # Select neighbor\n",
    "        nn_ = nn__[i]\n",
    "        step = steps[i]\n",
    "        # Create new sample\n",
    "        new[i, :] = X[y==1].iloc[sel] - step * (X[y==1].iloc[sel] - X[y==1].iloc[nn_])\n",
    "    \n",
    "    X = np.vstack((X, new))\n",
    "    y = np.append(y, np.ones(n_samples_1_new))\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9854733714884879 F1-Score: 0.0877914951989026 FBeta: 0.0707608100711549\n",
      "Accuracy: 0.9809078596705841 F1-Score: 0.07610993657505287 FBeta: 0.053966604823747676\n",
      "Accuracy: 0.9837913408187339 F1-Score: 0.09068627450980393 FBeta: 0.0687264367816092\n",
      "Accuracy: 0.9792695181091354 F1-Score: 0.07414634146341463 FBeta: 0.05098638326137496\n"
     ]
    }
   ],
   "source": [
    "for target_percentage in [0.25, 0.5]:\n",
    "    for k in [5, 15]:\n",
    "        X_u, y_u = SMOTE(X_train, y_train, target_percentage, k, seed=3)\n",
    "        logreg.fit(X_u,y_u)\n",
    "        y_pred=logreg.predict(X_test)\n",
    "        accuracy_scores.append(['SMOTE','logistic',target_percentage,k,metrics.accuracy_score(y_pred, y_test), metrics.f1_score(y_pred, y_test),metrics.fbeta_score(y_pred, y_test,10)])   \n",
    "\n",
    "        arbol.fit(X_u,y_u)\n",
    "        y_pred=arbol.predict(X_test)\n",
    "        accuracy_scores.append(['SMOTE','DecisionTree',target_percentage,k,metrics.accuracy_score(y_pred, y_test), metrics.f1_score(y_pred, y_test),metrics.fbeta_score(y_pred, y_test,10)])   \n",
    "\n",
    "        print(\"Accuracy:\",metrics.accuracy_score(y_pred, y_test),\"F1-Score:\",metrics.f1_score(y_pred, y_test),\"FBeta:\",metrics.fbeta_score(y_pred, y_test,10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.5 (3 points)\n",
    "\n",
    "Evaluate the results using Adaptive Synthetic Sampling Approach for Imbalanced\n",
    "Learning (ADASYN)\n",
    "\n",
    "http://www.ele.uri.edu/faculty/he/PDFfiles/adasyn.pdf\n",
    "https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.ADASYN.html#rf9172e970ca5-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import ADASYN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'IS_PYPY' from 'sklearn.utils' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-6fb02134dbb4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_classification\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\datasets\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mlfw\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfetch_lfw_pairs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mlfw\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfetch_lfw_people\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtwenty_newsgroups\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfetch_20newsgroups\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtwenty_newsgroups\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfetch_20newsgroups_vectorized\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmldata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfetch_mldata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmldata_filename\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\datasets\\twenty_newsgroups.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_fetch_remote\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRemoteFileMetadata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdict_vectorizer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDictVectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mhashing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFeatureHasher\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimg_to_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_to_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\hashing.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mIS_PYPY\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTransformerMixin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'IS_PYPY' from 'sklearn.utils' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_classes=2, class_sep=2,weights=[0.1, 0.9], n_informative=3, n_redundant=1, flip_y=0,n_features=20, n_clusters_per_class=1, n_samples=1000, random_state=10)\n",
    "print('Dataset original' % Counter(y))\n",
    "\n",
    "adasyn1 = ADASYN(random_state=1)\n",
    "X_u, y_u = adasyn1.fit_resample(X, y)\n",
    "print('Resampled Dataset' % Counter(y_u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target_percentage in np.arange(0.05,0.55, 0.05):\n",
    "        adasyn1 = ADASYN(random_state=1)\n",
    "        X_u, y_u  = adasyn1.fit_resample(X_train, y_train)\n",
    "            \n",
    "        logreg.fit(X_u,y_u)\n",
    "        y_pred=rf.predict(X_test)\n",
    "        accuracy_scores.append(['ADASYN','reg-log',target_percentage,-1,metrics.accuracy_score(y_pred, y_test), metrics.f1_score(y_pred, y_test),metrics.fbeta_score(y_pred, y_test,10)])   \n",
    "\n",
    "        arbol.fit(X_u,y_u)\n",
    "        y_pred=arbol.predict(X_test)\n",
    "        accuracy_scores.append(['ADASYN','DecisionTree',target_percentage,-1,metrics.accuracy_score(y_pred, y_test), metrics.f1_score(y_pred, y_test),metrics.fbeta_score(y_pred, y_test,10)])   \n",
    "\n",
    "        print(\"Accuracy:\",metrics.accuracy_score(y_pred, y_test),\"F1-Score:\",metrics.f1_score(y_pred, y_test),\"FBeta:\",metrics.fbeta_score(y_pred, y_test,10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.6 (3 points)\n",
    "\n",
    "Compare and comment about the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
