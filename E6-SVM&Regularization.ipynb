{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6\n",
    "\n",
    "## SVM & Regularization\n",
    "\n",
    "\n",
    "For this homework we consider a set of observations on a number of red and white wine varieties involving their chemical properties and ranking by tasters. Wine industry shows a recent growth spurt as social drinking is on the rise. The price of wine depends on a rather abstract concept of wine appreciation by wine tasters, opinion among whom may have a high degree of variability. Pricing of wine depends on such a volatile factor to some extent. Another key factor in wine certification and quality assessment is physicochemical tests which are laboratory-based and takes into account factors like acidity, pH level, presence of sugar and other chemical properties. For the wine market, it would be of interest if human quality of tasting can be related to the chemical properties of wine so that certification and quality assessment and assurance process is more controlled.\n",
    "\n",
    "Two datasets are available of which one dataset is on red wine and have 1599 different varieties and the other is on white wine and have 4898 varieties. All wines are produced in a particular area of Portugal. Data are collected on 12 different properties of the wines one of which is Quality, based on sensory data, and the rest are on chemical properties of the wines including density, acidity, alcohol content etc. All chemical properties of wines are continuous variables. Quality is an ordinal variable with possible ranking from 1 (worst) to 10 (best). Each variety of wine is tasted by three independent tasters and the final rank assigned is the median rank given by the tasters.\n",
    "\n",
    "A predictive model developed on this data is expected to provide guidance to vineyards regarding quality and price expected on their produce without heavy reliance on volatility of wine tasters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_r = pd.read_csv('https://github.com/albahnsen/PracticalMachineLearningClass/raw/master/datasets/Wine_data_red.csv')\n",
    "data_w = pd.read_csv('https://github.com/albahnsen/PracticalMachineLearningClass/raw/master/datasets/Wine_data_white.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.39</td>\n",
       "      <td>18.95</td>\n",
       "      <td>0.038</td>\n",
       "      <td>42.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0.99990</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0.47</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2982</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.31</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.050</td>\n",
       "      <td>29.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>0.99596</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.57</td>\n",
       "      <td>10.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>9.2</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.42</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.047</td>\n",
       "      <td>16.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.99517</td>\n",
       "      <td>3.09</td>\n",
       "      <td>0.66</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3913</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.054</td>\n",
       "      <td>24.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.99154</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.48</td>\n",
       "      <td>11.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3658</th>\n",
       "      <td>5.8</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.30</td>\n",
       "      <td>5.40</td>\n",
       "      <td>0.043</td>\n",
       "      <td>41.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.99260</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.42</td>\n",
       "      <td>10.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "410             7.2             0.250         0.39           18.95      0.038   \n",
       "2982            7.0             0.200         0.31            8.00      0.050   \n",
       "2400            9.2             0.190         0.42            2.00      0.047   \n",
       "3913            7.2             0.250         0.32            1.50      0.054   \n",
       "3658            5.8             0.275         0.30            5.40      0.043   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "410                  42.0                 155.0  0.99990  2.97       0.47   \n",
       "2982                 29.0                 213.0  0.99596  3.28       0.57   \n",
       "2400                 16.0                 104.0  0.99517  3.09       0.66   \n",
       "3913                 24.0                 105.0  0.99154  3.17       0.48   \n",
       "3658                 41.0                 149.0  0.99260  3.33       0.42   \n",
       "\n",
       "      alcohol  quality  \n",
       "410       9.0        6  \n",
       "2982     10.4        6  \n",
       "2400     10.0        4  \n",
       "3913     11.1        6  \n",
       "3658     10.8        7  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_w.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "6492            6.2             0.600         0.08             2.0      0.090   \n",
       "6493            5.9             0.550         0.10             2.2      0.062   \n",
       "6494            6.3             0.510         0.13             2.3      0.076   \n",
       "6495            5.9             0.645         0.12             2.0      0.075   \n",
       "6496            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "6492                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "6493                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "6494                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "6495                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "6496                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality type  \n",
       "6492     10.5        5  red  \n",
       "6493     11.2        6  red  \n",
       "6494     11.0        6  red  \n",
       "6495     10.2        5  red  \n",
       "6496     11.0        6  red  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_w.assign(type = 'white')\n",
    "data = data.append(data_r.assign(type = 'red'), ignore_index=True)\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.1\n",
    "\n",
    "Show the frecuency table of the quality by type of wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>quality</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>red</th>\n",
       "      <td>10</td>\n",
       "      <td>53</td>\n",
       "      <td>681</td>\n",
       "      <td>638</td>\n",
       "      <td>199</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white</th>\n",
       "      <td>20</td>\n",
       "      <td>163</td>\n",
       "      <td>1457</td>\n",
       "      <td>2198</td>\n",
       "      <td>880</td>\n",
       "      <td>175</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "quality   3    4     5     6    7    8  9\n",
       "type                                     \n",
       "red      10   53   681   638  199   18  0\n",
       "white    20  163  1457  2198  880  175  5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['type','quality']].pivot_table(index='type', columns='quality', aggfunc=len, fill_value=0)\n",
    "#pd.crosstab(data['type'],data['quality'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.2\n",
    "\n",
    "* Preparación de la data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definir una columna con la codificación de la calidad 1 o 0\n",
    "data['quality1'] = 0\n",
    "data['quality1'][data['quality']> 5] = 1\n",
    "data['quality1'].value_counts()\n",
    "\n",
    "d = {'white': 1, 'red': 0}\n",
    "data['type_bool'] = data['type'].map(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>type</th>\n",
       "      <th>quality1</th>\n",
       "      <th>type_bool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>8.2</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.080</td>\n",
       "      <td>24.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.99624</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.85</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>red</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592</th>\n",
       "      <td>5.6</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.27</td>\n",
       "      <td>3.90</td>\n",
       "      <td>0.043</td>\n",
       "      <td>52.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.99202</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.7</td>\n",
       "      <td>7</td>\n",
       "      <td>white</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.53</td>\n",
       "      <td>18.15</td>\n",
       "      <td>0.047</td>\n",
       "      <td>59.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.99920</td>\n",
       "      <td>3.09</td>\n",
       "      <td>0.52</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5205</th>\n",
       "      <td>10.3</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.42</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.213</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.99940</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.62</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "      <td>red</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3533</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.30</td>\n",
       "      <td>14.70</td>\n",
       "      <td>0.045</td>\n",
       "      <td>50.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.99704</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.37</td>\n",
       "      <td>10.6</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "6039            8.2              0.38         0.32            2.50      0.080   \n",
       "3592            5.6              0.28         0.27            3.90      0.043   \n",
       "469             7.2              0.29         0.53           18.15      0.047   \n",
       "5205           10.3              0.41         0.42            2.40      0.213   \n",
       "3533            6.6              0.22         0.30           14.70      0.045   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "6039                 24.0                  71.0  0.99624  3.27       0.85   \n",
       "3592                 52.0                 158.0  0.99202  3.35       0.44   \n",
       "469                  59.0                 182.0  0.99920  3.09       0.52   \n",
       "5205                  6.0                  14.0  0.99940  3.19       0.62   \n",
       "3533                 50.0                 136.0  0.99704  3.14       0.37   \n",
       "\n",
       "      alcohol  quality   type  quality1  type_bool  \n",
       "6039     11.0        6    red         1          0  \n",
       "3592     10.7        7  white         1          1  \n",
       "469       9.6        5  white         0          1  \n",
       "5205      9.5        6    red         1          0  \n",
       "3533     10.6        6  white         1          1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create two Linear SVM's for the white and red wines, repectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La precisión del modelo lineal para vinos rojos es: 0.603125\n"
     ]
    }
   ],
   "source": [
    "#Aplicación del modelo para vinos rojos.\n",
    "red_data = pd.DataFrame(data[data.type_bool == 0])\n",
    "\n",
    "X_red = np.array(red_data[['fixed acidity','volatile acidity', 'citric acid',\n",
    "                   'residual sugar','chlorides','free sulfur dioxide',\n",
    "                   'total sulfur dioxide','density','pH',\n",
    "                   'sulphates','alcohol']])\n",
    "\n",
    "y_red = np.array(red_data[['quality1']])\n",
    "\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_red, y_red, test_size=0.2, random_state=42)\n",
    "\n",
    "#Declara el modelo SVN\n",
    "clf = SVC(kernel='linear')\n",
    "#Estandariza X\n",
    "standardized_X = preprocessing.scale(X_train_r)\n",
    "#Calcula el modelo a partir de los datos de entrenamiento\n",
    "clf.fit(standardized_X, y_train_r)\n",
    "#Predice la respuesta a partir de los datos de prueba\n",
    "y_pred_r = clf.predict(X_test_r)\n",
    "#Métrica para medir la diferencia entre los y train y y_pred.\n",
    "print('La precisión del modelo lineal para vinos rojos es:',accuracy_score(y_test_r, y_pred_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La precisión del modelo lineal para vinos blancos es: 0.6806122448979591\n"
     ]
    }
   ],
   "source": [
    "#Aplicación del modelo para vinos blancos.\n",
    "white_data = pd.DataFrame(data[data.type_bool == 1])\n",
    "\n",
    "X_white = np.array(white_data[['fixed acidity','volatile acidity', 'citric acid',\n",
    "                   'residual sugar','chlorides','free sulfur dioxide',\n",
    "                   'total sulfur dioxide','density','pH',\n",
    "                   'sulphates','alcohol']])\n",
    "\n",
    "y_white = np.array(white_data[['quality1']])\n",
    "\n",
    "X_train_w, X_test_w, y_train_w, y_test_w = train_test_split(X_white, y_white, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = SVC(kernel='linear')\n",
    "standardized_X = preprocessing.scale(X_train_w)\n",
    "clf.fit(standardized_X, y_train_w)\n",
    "y_pred_w = clf.predict(X_test_w)\n",
    "print('La precisión del modelo lineal para vinos blancos es:',accuracy_score(y_test_w, y_pred_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.3\n",
    "\n",
    "Test the two SVM's using the different kernels (‘poly’, ‘rbf’, ‘sigmoid’)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión Modelos Vino rojo\n",
      "poly: 0.603\n",
      "rbf: 0.603\n",
      "sigmoid: 0.603\n"
     ]
    }
   ],
   "source": [
    "print('Precisión Modelos Vino rojo')\n",
    "\n",
    "clf = SVC(kernel='poly')\n",
    "standardized_X = preprocessing.scale(X_train_r)\n",
    "clf.fit(standardized_X, y_train_r)\n",
    "y_pred_w = clf.predict(X_test_r)\n",
    "print('poly:',round(accuracy_score(y_test_r, y_pred_r),3))\n",
    "\n",
    "clf = SVC(kernel='rbf')\n",
    "standardized_X = preprocessing.scale(X_train_r)\n",
    "clf.fit(standardized_X, y_train_r)\n",
    "y_pred_w = clf.predict(X_test_r)\n",
    "print('rbf:',round(accuracy_score(y_test_r, y_pred_r),3))\n",
    "\n",
    "clf = SVC(kernel='sigmoid')\n",
    "standardized_X = preprocessing.scale(X_train_r)\n",
    "clf.fit(standardized_X, y_train_r)\n",
    "y_pred_w = clf.predict(X_test_r)\n",
    "print('sigmoid:',round(accuracy_score(y_test_r, y_pred_r),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión Modelos Vino blanco\n",
      "poly: 0.672\n",
      "rbf: 0.672\n",
      "sigmoid: 0.674\n"
     ]
    }
   ],
   "source": [
    "print('Precisión Modelos Vino blanco')\n",
    "\n",
    "clf = SVC(kernel='poly')\n",
    "standardized_X = preprocessing.scale(X_train_w)\n",
    "clf.fit(standardized_X, y_train_w)\n",
    "y_pred_w = clf.predict(X_test_w)\n",
    "print('poly:',round(accuracy_score(y_test_w, y_pred_w),3))\n",
    "\n",
    "clf = SVC(kernel='rbf')\n",
    "standardized_X = preprocessing.scale(X_train_w)\n",
    "clf.fit(standardized_X, y_train_w)\n",
    "y_pred_w = clf.predict(X_test_w)\n",
    "print('rbf:',round(accuracy_score(y_test_w, y_pred_w),3))\n",
    "\n",
    "clf = SVC(kernel='sigmoid')\n",
    "standardized_X = preprocessing.scale(X_train_w)\n",
    "clf.fit(standardized_X, y_train_w)\n",
    "y_pred_w = clf.predict(X_test_w)\n",
    "print('sigmoid:',round(accuracy_score(y_test_w, y_pred_w),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.4\n",
    "Using the best SVM find the parameters that gives the best performance\n",
    "\n",
    "'C': [0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.001, 0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "C=[ 0.1, 1, 10, 100, 1000]\n",
    "gamma=[0.01, 0.001, 0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:  0.1 / gamma:  0.01 / Accuracy:  0.49375\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.46      0.77      0.57       141\n",
      "          1       0.60      0.28      0.38       179\n",
      "\n",
      "avg / total       0.54      0.49      0.47       320\n",
      "\n",
      "C:  0.1 / gamma:  0.001 / Accuracy:  0.55625\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       141\n",
      "          1       0.56      0.99      0.71       179\n",
      "\n",
      "avg / total       0.31      0.56      0.40       320\n",
      "\n",
      "C:  0.1 / gamma:  0.0001 / Accuracy:  0.559375\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       141\n",
      "          1       0.56      1.00      0.72       179\n",
      "\n",
      "avg / total       0.31      0.56      0.40       320\n",
      "\n",
      "C:  1 / gamma:  0.01 / Accuracy:  0.41875\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.42      0.89      0.57       141\n",
      "          1       0.36      0.05      0.09       179\n",
      "\n",
      "avg / total       0.39      0.42      0.30       320\n",
      "\n",
      "C:  1 / gamma:  0.001 / Accuracy:  0.553125\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       141\n",
      "          1       0.56      0.99      0.71       179\n",
      "\n",
      "avg / total       0.31      0.55      0.40       320\n",
      "\n",
      "C:  1 / gamma:  0.0001 / Accuracy:  0.559375\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       141\n",
      "          1       0.56      1.00      0.72       179\n",
      "\n",
      "avg / total       0.31      0.56      0.40       320\n",
      "\n",
      "C:  10 / gamma:  0.01 / Accuracy:  0.440625\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      1.00      0.61       141\n",
      "          1       0.00      0.00      0.00       179\n",
      "\n",
      "avg / total       0.19      0.44      0.27       320\n",
      "\n",
      "C:  10 / gamma:  0.001 / Accuracy:  0.565625\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.04      0.07       141\n",
      "          1       0.56      0.98      0.72       179\n",
      "\n",
      "avg / total       0.59      0.57      0.43       320\n",
      "\n",
      "C:  10 / gamma:  0.0001 / Accuracy:  0.559375\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       141\n",
      "          1       0.56      1.00      0.72       179\n",
      "\n",
      "avg / total       0.31      0.56      0.40       320\n",
      "\n",
      "C:  100 / gamma:  0.01 / Accuracy:  0.440625\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      1.00      0.61       141\n",
      "          1       0.00      0.00      0.00       179\n",
      "\n",
      "avg / total       0.19      0.44      0.27       320\n",
      "\n",
      "C:  100 / gamma:  0.001 / Accuracy:  0.5875\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.15      0.24       141\n",
      "          1       0.58      0.93      0.72       179\n",
      "\n",
      "avg / total       0.61      0.59      0.51       320\n",
      "\n",
      "C:  100 / gamma:  0.0001 / Accuracy:  0.559375\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       141\n",
      "          1       0.56      1.00      0.72       179\n",
      "\n",
      "avg / total       0.31      0.56      0.40       320\n",
      "\n",
      "C:  1000 / gamma:  0.01 / Accuracy:  0.440625\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      1.00      0.61       141\n",
      "          1       0.00      0.00      0.00       179\n",
      "\n",
      "avg / total       0.19      0.44      0.27       320\n",
      "\n",
      "C:  1000 / gamma:  0.001 / Accuracy:  0.615625\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.33      0.43       141\n",
      "          1       0.61      0.84      0.71       179\n",
      "\n",
      "avg / total       0.62      0.62      0.59       320\n",
      "\n",
      "C:  1000 / gamma:  0.0001 / Accuracy:  0.559375\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       141\n",
      "          1       0.56      1.00      0.72       179\n",
      "\n",
      "avg / total       0.31      0.56      0.40       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Definición de parámetros óptimos para el modelo poly sobre la base de vinos rojos\n",
    "\n",
    "standardized_X = preprocessing.scale(X_train_r)\n",
    "\n",
    "for c in C:\n",
    "    for g in gamma:\n",
    "        ## Poly\n",
    "        clf = SVC(kernel='poly',degree=7,C=c,gamma=g)\n",
    "        clf.fit(standardized_X, y_train_r)\n",
    "        y_pred_r = clf.predict(X_test_r)  \n",
    "        print(\"C: \",c,\"/ gamma: \",g, \"/ Accuracy: \",accuracy_score(y_test_r,y_pred_r))\n",
    "        print(classification_report(y_test_r,y_pred_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los parámetros óptimos para el SVN poly para los vinos blancos son:\n",
    "\n",
    "C:  0.1\n",
    "gamma:  0.0001\n",
    "Accuracy:  0.559375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:  0.1 / gamma:  0.01 / Accuracy:  0.32653061224489793\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      1.00      0.49       321\n",
      "          1       0.00      0.00      0.00       659\n",
      "\n",
      "avg / total       0.11      0.33      0.16       980\n",
      "\n",
      "C:  0.1 / gamma:  0.001 / Accuracy:  0.6795918367346939\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.07      0.13       321\n",
      "          1       0.68      0.98      0.80       659\n",
      "\n",
      "avg / total       0.65      0.68      0.58       980\n",
      "\n",
      "C:  0.1 / gamma:  0.0001 / Accuracy:  0.6724489795918367\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       321\n",
      "          1       0.67      1.00      0.80       659\n",
      "\n",
      "avg / total       0.45      0.67      0.54       980\n",
      "\n",
      "C:  1 / gamma:  0.01 / Accuracy:  0.32653061224489793\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      1.00      0.49       321\n",
      "          1       0.00      0.00      0.00       659\n",
      "\n",
      "avg / total       0.11      0.33      0.16       980\n",
      "\n",
      "C:  1 / gamma:  0.001 / Accuracy:  0.6377551020408163\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      0.43      0.44       321\n",
      "          1       0.73      0.74      0.73       659\n",
      "\n",
      "avg / total       0.63      0.64      0.64       980\n",
      "\n",
      "C:  1 / gamma:  0.0001 / Accuracy:  0.6724489795918367\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       321\n",
      "          1       0.67      1.00      0.80       659\n",
      "\n",
      "avg / total       0.45      0.67      0.54       980\n",
      "\n",
      "C:  10 / gamma:  0.01 / Accuracy:  0.32755102040816325\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      1.00      0.49       321\n",
      "          1       0.00      0.00      0.00       659\n",
      "\n",
      "avg / total       0.11      0.33      0.16       980\n",
      "\n",
      "C:  10 / gamma:  0.001 / Accuracy:  0.45816326530612245\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.35      0.73      0.47       321\n",
      "          1       0.71      0.32      0.45       659\n",
      "\n",
      "avg / total       0.59      0.46      0.45       980\n",
      "\n",
      "C:  10 / gamma:  0.0001 / Accuracy:  0.6724489795918367\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       321\n",
      "          1       0.67      1.00      0.80       659\n",
      "\n",
      "avg / total       0.45      0.67      0.54       980\n",
      "\n",
      "C:  100 / gamma:  0.01 / Accuracy:  0.32755102040816325\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      1.00      0.49       321\n",
      "          1       0.00      0.00      0.00       659\n",
      "\n",
      "avg / total       0.11      0.33      0.16       980\n",
      "\n",
      "C:  100 / gamma:  0.001 / Accuracy:  0.34285714285714286\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.32      0.91      0.48       321\n",
      "          1       0.60      0.07      0.12       659\n",
      "\n",
      "avg / total       0.51      0.34      0.24       980\n",
      "\n",
      "C:  100 / gamma:  0.0001 / Accuracy:  0.6724489795918367\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       321\n",
      "          1       0.67      1.00      0.80       659\n",
      "\n",
      "avg / total       0.45      0.67      0.54       980\n",
      "\n",
      "C:  1000 / gamma:  0.01 / Accuracy:  0.6663265306122449\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.39      0.03      0.06       321\n",
      "          1       0.67      0.97      0.80       659\n",
      "\n",
      "avg / total       0.58      0.67      0.56       980\n",
      "\n",
      "C:  1000 / gamma:  0.001 / Accuracy:  0.32142857142857145\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.32      0.97      0.48       321\n",
      "          1       0.31      0.01      0.01       659\n",
      "\n",
      "avg / total       0.32      0.32      0.17       980\n",
      "\n",
      "C:  1000 / gamma:  0.0001 / Accuracy:  0.673469387755102\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.00      0.01       321\n",
      "          1       0.67      1.00      0.80       659\n",
      "\n",
      "avg / total       0.78      0.67      0.54       980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Definición de parámetros óptimos para el modelo poly sobre la base de vinos blancos\n",
    "\n",
    "standardized_X = preprocessing.scale(X_train_w)\n",
    "\n",
    "for c in C:\n",
    "    for g in gamma:\n",
    "        ## Poly\n",
    "        clf = SVC(kernel='poly',degree=7,C=c,gamma=g)\n",
    "        clf.fit(standardized_X, y_train_w)\n",
    "        y_pred_w = clf.predict(X_test_w)  \n",
    "        print(\"C: \",c,\"/ gamma: \",g, \"/ Accuracy: \",accuracy_score(y_test_w,y_pred_w))\n",
    "        #print(confusion_matrix(y_test_w,y_pred_w)) \n",
    "        print(classification_report(y_test_w,y_pred_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los parámetros óptimos para el SVN poly para los vinos blancos son:\n",
    "\n",
    "C:  0.1\n",
    "gamma:  0.001\n",
    "Accuracy:  0.6795918367346939"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.5\n",
    "\n",
    "Compare the results with other methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:  0.1 / gamma:  0.01 / Accuracy:  0.434375\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      0.99      0.61       141\n",
      "          1       0.00      0.00      0.00       179\n",
      "\n",
      "avg / total       0.19      0.43      0.27       320\n",
      "\n",
      "C:  0.1 / gamma:  0.001 / Accuracy:  0.559375\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       141\n",
      "          1       0.56      1.00      0.72       179\n",
      "\n",
      "avg / total       0.31      0.56      0.40       320\n",
      "\n",
      "C:  0.1 / gamma:  0.0001 / Accuracy:  0.559375\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       141\n",
      "          1       0.56      1.00      0.72       179\n",
      "\n",
      "avg / total       0.31      0.56      0.40       320\n",
      "\n",
      "C:  1 / gamma:  0.01 / Accuracy:  0.440625\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      1.00      0.61       141\n",
      "          1       0.00      0.00      0.00       179\n",
      "\n",
      "avg / total       0.19      0.44      0.27       320\n",
      "\n",
      "C:  1 / gamma:  0.001 / Accuracy:  0.509375\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.77      0.58       141\n",
      "          1       0.62      0.31      0.41       179\n",
      "\n",
      "avg / total       0.55      0.51      0.49       320\n",
      "\n",
      "C:  1 / gamma:  0.0001 / Accuracy:  0.575\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.64      0.57       141\n",
      "          1       0.65      0.53      0.58       179\n",
      "\n",
      "avg / total       0.59      0.57      0.58       320\n",
      "\n",
      "C:  10 / gamma:  0.01 / Accuracy:  0.440625\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      1.00      0.61       141\n",
      "          1       0.00      0.00      0.00       179\n",
      "\n",
      "avg / total       0.19      0.44      0.27       320\n",
      "\n",
      "C:  10 / gamma:  0.001 / Accuracy:  0.484375\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.45      0.81      0.58       141\n",
      "          1       0.60      0.23      0.33       179\n",
      "\n",
      "avg / total       0.54      0.48      0.44       320\n",
      "\n",
      "C:  10 / gamma:  0.0001 / Accuracy:  0.53125\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      0.73      0.58       141\n",
      "          1       0.64      0.37      0.47       179\n",
      "\n",
      "avg / total       0.57      0.53      0.52       320\n",
      "\n",
      "C:  100 / gamma:  0.01 / Accuracy:  0.440625\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      1.00      0.61       141\n",
      "          1       0.00      0.00      0.00       179\n",
      "\n",
      "avg / total       0.19      0.44      0.27       320\n",
      "\n",
      "C:  100 / gamma:  0.001 / Accuracy:  0.440625\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      0.99      0.61       141\n",
      "          1       0.50      0.01      0.02       179\n",
      "\n",
      "avg / total       0.47      0.44      0.28       320\n",
      "\n",
      "C:  100 / gamma:  0.0001 / Accuracy:  0.5875\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.67      0.59       141\n",
      "          1       0.67      0.52      0.58       179\n",
      "\n",
      "avg / total       0.61      0.59      0.59       320\n",
      "\n",
      "C:  1000 / gamma:  0.01 / Accuracy:  0.440625\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      1.00      0.61       141\n",
      "          1       0.00      0.00      0.00       179\n",
      "\n",
      "avg / total       0.19      0.44      0.27       320\n",
      "\n",
      "C:  1000 / gamma:  0.001 / Accuracy:  0.440625\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      1.00      0.61       141\n",
      "          1       0.00      0.00      0.00       179\n",
      "\n",
      "avg / total       0.19      0.44      0.27       320\n",
      "\n",
      "C:  1000 / gamma:  0.0001 / Accuracy:  0.5125\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.76      0.58       141\n",
      "          1       0.63      0.32      0.42       179\n",
      "\n",
      "avg / total       0.56      0.51      0.49       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Definición de parámetros óptimos para el modelo rbf sobre la base de vinos rojos\n",
    "\n",
    "standardized_X = preprocessing.scale(X_train_r)\n",
    "\n",
    "for c in C:\n",
    "    for g in gamma:\n",
    "        ## Poly\n",
    "        clf = SVC(kernel='rbf',degree=7,C=c,gamma=g)\n",
    "        clf.fit(standardized_X, y_train_r)\n",
    "        y_pred_r = clf.predict(X_test_r)  \n",
    "        print(\"C: \",c,\"/ gamma: \",g, \"/ Accuracy: \",accuracy_score(y_test_r,y_pred_r))\n",
    "        print(classification_report(y_test_r,y_pred_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:  0.1 / gamma:  0.01 / Accuracy:  0.32653061224489793\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      1.00      0.49       321\n",
      "          1       0.00      0.00      0.00       659\n",
      "\n",
      "avg / total       0.11      0.33      0.16       980\n",
      "\n",
      "C:  0.1 / gamma:  0.001 / Accuracy:  0.6724489795918367\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       321\n",
      "          1       0.67      1.00      0.80       659\n",
      "\n",
      "avg / total       0.45      0.67      0.54       980\n",
      "\n",
      "C:  0.1 / gamma:  0.0001 / Accuracy:  0.6724489795918367\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       321\n",
      "          1       0.67      1.00      0.80       659\n",
      "\n",
      "avg / total       0.45      0.67      0.54       980\n",
      "\n",
      "C:  1 / gamma:  0.01 / Accuracy:  0.6724489795918367\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       321\n",
      "          1       0.67      1.00      0.80       659\n",
      "\n",
      "avg / total       0.45      0.67      0.54       980\n",
      "\n",
      "C:  1 / gamma:  0.001 / Accuracy:  0.32346938775510203\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.32      0.98      0.49       321\n",
      "          1       0.17      0.00      0.00       659\n",
      "\n",
      "avg / total       0.22      0.32      0.16       980\n",
      "\n",
      "C:  1 / gamma:  0.0001 / Accuracy:  0.6724489795918367\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       321\n",
      "          1       0.67      1.00      0.80       659\n",
      "\n",
      "avg / total       0.45      0.67      0.54       980\n",
      "\n",
      "C:  10 / gamma:  0.01 / Accuracy:  0.32755102040816325\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      1.00      0.49       321\n",
      "          1       0.00      0.00      0.00       659\n",
      "\n",
      "avg / total       0.11      0.33      0.16       980\n",
      "\n",
      "C:  10 / gamma:  0.001 / Accuracy:  0.6612244897959184\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.35      0.04      0.07       321\n",
      "          1       0.67      0.96      0.79       659\n",
      "\n",
      "avg / total       0.57      0.66      0.56       980\n",
      "\n",
      "C:  10 / gamma:  0.0001 / Accuracy:  0.5867346938775511\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.42      0.72      0.53       321\n",
      "          1       0.79      0.52      0.63       659\n",
      "\n",
      "avg / total       0.67      0.59      0.60       980\n",
      "\n",
      "C:  100 / gamma:  0.01 / Accuracy:  0.32755102040816325\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      1.00      0.49       321\n",
      "          1       0.00      0.00      0.00       659\n",
      "\n",
      "avg / total       0.11      0.33      0.16       980\n",
      "\n",
      "C:  100 / gamma:  0.001 / Accuracy:  0.32551020408163267\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.99      0.49       321\n",
      "          1       0.00      0.00      0.00       659\n",
      "\n",
      "avg / total       0.11      0.33      0.16       980\n",
      "\n",
      "C:  100 / gamma:  0.0001 / Accuracy:  0.39081632653061227\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.81      0.46       321\n",
      "          1       0.67      0.19      0.29       659\n",
      "\n",
      "avg / total       0.56      0.39      0.35       980\n",
      "\n",
      "C:  1000 / gamma:  0.01 / Accuracy:  0.32755102040816325\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      1.00      0.49       321\n",
      "          1       0.00      0.00      0.00       659\n",
      "\n",
      "avg / total       0.11      0.33      0.16       980\n",
      "\n",
      "C:  1000 / gamma:  0.001 / Accuracy:  0.32448979591836735\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.32      0.98      0.49       321\n",
      "          1       0.29      0.00      0.01       659\n",
      "\n",
      "avg / total       0.30      0.32      0.16       980\n",
      "\n",
      "C:  1000 / gamma:  0.0001 / Accuracy:  0.32346938775510203\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.32      0.98      0.49       321\n",
      "          1       0.17      0.00      0.00       659\n",
      "\n",
      "avg / total       0.22      0.32      0.16       980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Definición de parámetros óptimos para el modelo poly sobre la base de vinos blancos\n",
    "\n",
    "standardized_X = preprocessing.scale(X_train_w)\n",
    "\n",
    "for c in C:\n",
    "    for g in gamma:\n",
    "        ## Poly\n",
    "        clf = SVC(kernel='rbf',degree=7,C=c,gamma=g)\n",
    "        clf.fit(standardized_X, y_train_w)\n",
    "        y_pred_w = clf.predict(X_test_w)  \n",
    "        print(\"C: \",c,\"/ gamma: \",g, \"/ Accuracy: \",accuracy_score(y_test_w,y_pred_w))\n",
    "        #print(confusion_matrix(y_test_w,y_pred_w)) \n",
    "        print(classification_report(y_test_w,y_pred_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.6\n",
    "\n",
    "\n",
    "* Train a linear regression to predict wine quality (Continous)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data[['fixed acidity','volatile acidity', 'citric acid',\n",
    "                   'residual sugar','chlorides','free sulfur dioxide',\n",
    "                   'total sulfur dioxide','density','pH',\n",
    "                   'sulphates','alcohol']])\n",
    "\n",
    "y = np.array(data[['quality']])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Initialize\n",
    "linreg = LinearRegression(fit_intercept=False)\n",
    "# Fit\n",
    "linreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = linreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Analyze the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01123191, -1.44251231, -0.10053734,  0.02319971, -0.65374668,\n",
       "         0.00636245, -0.00244575,  2.00929887,  0.13921813,  0.6621809 ,\n",
       "         0.32959046]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al observar los coeficientes, se ve que la gran mayoría de ellos indican variables con significacncia para el modelo lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Evaluate the RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.6920917977650142\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "print('MSE:', sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.7\n",
    "\n",
    "* Estimate a ridge regression with alpha equals 0.1 and 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha=0.1\n",
    "from sklearn.linear_model import Ridge\n",
    "ridgereg01 = Ridge(alpha=0.1, normalize=True)\n",
    "ridgereg01.fit(X_train, y_train)\n",
    "y_pred = ridgereg01.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.90911851e-02, -1.15638289e+00,  2.58061347e-02,\n",
       "         2.69505448e-02, -8.80349904e-01,  4.85795553e-03,\n",
       "        -1.96916472e-03, -2.88186411e+01,  2.27099214e-01,\n",
       "         6.68265776e-01,  2.58453034e-01]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridgereg01.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.6923968765515969\n"
     ]
    }
   ],
   "source": [
    "print('MSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha=1\n",
    "from sklearn.linear_model import Ridge\n",
    "ridgereg = Ridge(alpha=1, normalize=True)\n",
    "ridgereg.fit(X_train, y_train)\n",
    "y_pred = ridgereg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.86548358e-04, -5.72959670e-01,  1.73567247e-01,\n",
       "         6.00456832e-03, -1.25598585e+00,  1.66021236e-03,\n",
       "        -6.35899542e-04, -2.18758539e+01,  7.70463388e-02,\n",
       "         3.12457632e-01,  1.37364728e-01]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridgereg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.7300937224503552\n"
     ]
    }
   ],
   "source": [
    "print('MSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.8\n",
    "\n",
    "* Estimate a lasso regression with alpha equals 0.01, 0.1 and 1.\n",
    "* Compare the coefficients with the linear regression\n",
    "* Evaluate the RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00000000e+00 -1.09406553e+00  0.00000000e+00  6.89306915e-03\n",
      " -0.00000000e+00  4.77392494e-04 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  3.69277283e-01  2.95976005e-01]\n",
      "MSE: 0.7300937224503552\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lassoreg = Lasso(alpha=0.0005, normalize=True)\n",
    "lassoreg.fit(X_train, y_train)\n",
    "print(lassoreg.coef_)\n",
    "print('MSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0. -0.  0. -0. -0.  0. -0. -0.  0.  0.  0.]\n",
      "MSE: 0.7300937224503552\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lassoreg = Lasso(alpha=0.01, normalize=True)\n",
    "lassoreg.fit(X_train, y_train)\n",
    "print(lassoreg.coef_)\n",
    "print('MSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0. -0.  0. -0. -0.  0. -0. -0.  0.  0.  0.]\n",
      "MSE: 0.7300937224503552\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lassoreg = Lasso(alpha=1, normalize=True)\n",
    "lassoreg.fit(X_train, y_train)\n",
    "print(lassoreg.coef_)\n",
    "print('MSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.9\n",
    "\n",
    "* Create a binary target\n",
    "\n",
    "* Train a logistic regression to predict wine quality (binary)\n",
    "\n",
    "* Analyze the coefficients\n",
    "\n",
    "* Evaluate the f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data[['fixed acidity','volatile acidity', 'citric acid',\n",
    "                   'residual sugar','chlorides','free sulfur dioxide',\n",
    "                   'total sulfur dioxide','density','pH',\n",
    "                   'sulphates','alcohol']])\n",
    "\n",
    "y = np.array(data[['quality1']])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a logistic regression model and store the class predictions\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(solver='liblinear',C=1e9)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03797515, -4.41668794, -0.55810775,  0.07106798, -1.0722782 ,\n",
       "         0.01780072, -0.00787689, -5.02832196,  0.51686001,  1.94753138,\n",
       "         0.90954524]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.60      0.63       468\n",
      "          1       0.79      0.83      0.81       832\n",
      "\n",
      "avg / total       0.74      0.75      0.74      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.10\n",
    "\n",
    "* Estimate a regularized logistic regression using:\n",
    "* C = 0.01, 0.1 & 1.0\n",
    "* penalty = ['l1, 'l2']\n",
    "* Compare the coefficients and the f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [0.01, 0.1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in C:\n",
    "    clf_l1_LR = LogisticRegression(C=c, penalty='l1', tol=0.01, solver='saga')\n",
    "    clf_l2_LR = LogisticRegression(C=c, penalty='l2', tol=0.01, solver='saga')\n",
    "    clf_l1_LR.fit(X_train, y_train)\n",
    "    clf_l2_LR.fit(X_train, y_train)\n",
    "    \n",
    "    coef1 = clf_l1_LR.coef_.ravel()\n",
    "    coef2 = clf_l2_LR.coef_.ravel()\n",
    "    \n",
    "    y_pred1 = clf_l1_LR.predict(X_test)\n",
    "    y_pred2 = clf_l2_LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.17      0.25       468\n",
      "          1       0.66      0.91      0.76       832\n",
      "\n",
      "avg / total       0.60      0.64      0.58      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.12      0.19       468\n",
      "          1       0.65      0.93      0.77       832\n",
      "\n",
      "avg / total       0.59      0.64      0.56      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
